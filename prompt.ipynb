{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "# llm.invoke(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5285ea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='what is the capital of france?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-10-23T17:30:17.408452Z', 'done': True, 'done_reason': 'stop', 'total_duration': 682662875, 'load_duration': 567317833, 'prompt_eval_count': 32, 'prompt_eval_duration': 65070791, 'eval_count': 8, 'eval_duration': 46029376, 'model_name': 'llama3.2:1b'}, id='run--7604e231-8550-4b07-a76b-f2d846550255-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"what is the capital of {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\": \"france\"})\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc656ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"If you want to know the capital of a specific country, I'd be happy to help.\\n\\nFor example, if you want to know the capital of Japan, it's Tokyo. If you want to know the capital of China, it's Beijing. Let me know which country you're interested in, and I'll do my best to provide the correct answer!\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-10-23T17:18:54.346156Z', 'done': True, 'done_reason': 'stop', 'total_duration': 637152333, 'load_duration': 94054667, 'prompt_eval_count': 87, 'prompt_eval_duration': 43315292, 'eval_count': 73, 'eval_duration': 475075253, 'model_name': 'llama3.2:1b'}, id='run--120c720a-0976-4bf7-b862-30d70285f2bf-0', usage_metadata={'input_tokens': 87, 'output_tokens': 73, 'total_tokens': 160})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "message_list = [\n",
    "    SystemMessage(content=\"you a helpful assistant!\"),\n",
    "    HumanMessage(content=\"what is the capital of france?\"),\n",
    "    AIMessage(content=\"the capital of france is paris.\"),\n",
    "    HumanMessage(content=\"what is the capital of germany?\"),\n",
    "    AIMessage(content=\"the capital of france is berlin.\"),\n",
    "    # HumanMessage(content=\"what is the capital of italy?\"), # PromptTemplate 실습시\n",
    "    HumanMessage(content=\"what is the capital of {country}}?\"), # ChatPromptTemplate 실습시\n",
    "]\n",
    "\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "514791e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"you're a helpful assistant!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the capital of italy?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# chat_prompt_template = ChatPromptTemplate.from_messages(message_list)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant!\"),\n",
    "    (\"human\", \"what is the capital of {country}?\"),\n",
    "])\n",
    "\n",
    "chat_prompt = chat_prompt_template.invoke({\"country\": \"italy\"})\n",
    "\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e39e46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a helpful assistant!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is the capital of italy?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
